{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-induced activity propogation and modeling activity change on node-level in a minimal neural network accounting for network connectivity\n",
    "\n",
    "Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import custom modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'helpers')))\n",
    "from eGLM_model import default_args, generateStructuralNetwork, generateSynapticNetwork, networkModel\n",
    "from eGLM_helpers import phi, run_ucr_glm, run_ext_glm, make_stimtimes, sim_network_task_glm,  get_true_baseline, plot_sim_network_glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_args = copy(default_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network structure\n",
    "\n",
    "Goal of this notebook: Create the most minimal RNN that will be used in the more extended simulations to understand how activity propogates depending on the various parameters.\n",
    "\n",
    "The network model describes change in activity as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{dx_i}{dt}\\tau_i = -x_i(t) + s\\phi\\big(x_i(t)\\big) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(x_j(t)\\big)\\Bigg) + I_i(t)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create network with 9 nodes with the following connectivity matrix. The first community (nodes 0-2) is a hub community and the other two are local communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_args.update({'hubnetwork_dsity': .5, \"nodespercommunity\":3, 'showplot':True})\n",
    "sim_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct structural matrix\n",
    "S = generateStructuralNetwork(args_dict = sim_args)\n",
    "\n",
    "plt.hlines(y=2.5, xmin = -0.5, xmax = 8.5)\n",
    "plt.hlines(y=5.5, xmin = -0.5, xmax = 8.5)\n",
    "plt.vlines(x=2.5, ymin = -0.5, ymax = 8.5)\n",
    "plt.vlines(x=5.5, ymin = -0.5, ymax = 8.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in this matrix:\n",
    "\n",
    "`W[..., x]` : column x of matrix denotes all outgoing connection weights from node x  \n",
    "`W[x, ...]` : row x of matrix denotes all incoming connection weights to node x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct synaptic matrix\n",
    "W = generateSynapticNetwork(S, showplot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.arange(0,sim_args['Tmax'],sim_args['dt'])\n",
    "\n",
    "# Construct a community affiliation vector\n",
    "Ci = np.repeat(np.arange(sim_args['ncommunities']),sim_args['nodespercommunity']) \n",
    "# Identify the regions associated with the hub network (hub network is by default the 0th network)\n",
    "hub_ind = np.where(Ci==0)[0] \n",
    "\n",
    "stimsize = sim_args['nodespercommunity']\n",
    "\n",
    "# This works because if there is a hub network the first nodes are the hub nodes\n",
    "stim_nodes_td = np.arange(0, stimsize, dtype=int)\n",
    "#stim_nodes_td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task structure\n",
    "\n",
    "This network is stimulated topdown (i.e. only the hub nodes) with the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasktiming, stimtimes = make_stimtimes(stim_nodes= stim_nodes_td, args_dict=sim_args)\n",
    "plt.plot(tasktiming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stimtimes describes amount of stimulation (controlled by stim_mag) in each node for all time points\n",
    "sim_args.update({'I':stimtimes})\n",
    "taskdata, _ = networkModel(W, args_dict=sim_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network activity time course\n",
    "\n",
    "Timeseries/activity for each node in each community.  \n",
    "\n",
    "Since only the hub network is stimulated by the task the amount of activity will depend on number (/strength) of incoming connections from hub network nodes. If a node does not have any incoming connections from the hub network its activity will not change from 0.\n",
    "\n",
    "Connections from the hub community to the other communities can be checked on the columns going out of the hub nodes (in this case the first three columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize what is going on on the network\n",
    "#Three scatter plots with three curves for the timeseries/activity of each node in that community\n",
    "taskdata_df = pd.DataFrame(taskdata)\n",
    "taskdata_df['node_num'] = taskdata_df.index\n",
    "taskdata_df['com_num'] = [0,0,0,1,1,1,2,2,2]\n",
    "taskdata_df = taskdata_df.melt(id_vars = ['node_num', 'com_num'])\n",
    "taskdata_df = taskdata_df.rename(columns={\"variable\": \"time\", \"value\": \"activity\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 20\n",
    "plt.rcParams[\"figure.figsize\"][1] = 5\n",
    "fig, a = plt.subplots(1, 3)\n",
    "\n",
    "for cur_com in taskdata_df.com_num.unique():\n",
    "    \n",
    "    cur_vals = [\"C\"+str(x) for x in range(len(taskdata_df.query(\"com_num==@cur_com\").node_num.unique()))]\n",
    "    cur_col_lookup = dict(zip(taskdata_df.query(\"com_num==@cur_com\").node_num.unique(), cur_vals))\n",
    "    \n",
    "    for cur_node in taskdata_df.query(\"com_num==@cur_com\").node_num.unique():\n",
    "        tmp = taskdata_df.query(\"com_num==@cur_com & node_num==@cur_node\")\n",
    "        a[cur_com].plot(tmp['time'], tmp['activity'], color = cur_col_lookup[cur_node], label = cur_node)\n",
    "        a[cur_com].set_ylim([-0.2,2])\n",
    "        a[cur_com].set_title(\"com_num = %s\"%(str(cur_com)))\n",
    "        a[cur_com].legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that activity builds up and decreases in several time steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 14\n",
    "plt.rcParams[\"figure.figsize\"][1] = 5\n",
    "fig, a = plt.subplots(1, 2)\n",
    "\n",
    "node = 0\n",
    "task_on_t = np.where(np.diff(tasktiming) != 0)[0][0]\n",
    "task_off_t = np.where(np.diff(tasktiming) != 0)[0][1]\n",
    "range_start = 45\n",
    "range_end = 70\n",
    "plt_ranges = [range(range_start, range_end), range(range_start+50, range_end+50)]\n",
    "\n",
    "a[0].plot(taskdata[node, plt_ranges[0]])\n",
    "a[0].annotate(\"Task On\", xy=(task_on_t - range_start-1, 0.35), xytext=(task_on_t - range_start-1, 0.35))\n",
    "a[0].arrow(task_on_t - range_start, 0.3, 0, -0.2, head_width=0.5, head_length=0.1, fc='k', ec='k')\n",
    "a[0].set_xticks([])\n",
    "a[0].set_yticks([])\n",
    "a[0].set_xlabel(\"Time\")\n",
    "a[0].set_ylabel(\"Activity\")\n",
    "a[0].set_ylim([-0.2,2])\n",
    "\n",
    "a[1].plot(taskdata[node, plt_ranges[1]])\n",
    "a[1].annotate(\"Task Off\", xy=(task_off_t - (range_start+50)-1,  max(taskdata[node]) - .4), xytext=(task_off_t - (range_start+50)-1,  max(taskdata[node]) - .4))\n",
    "a[1].arrow(task_off_t - (range_start+50), max(taskdata[node]) - .3, 0, 0.2, head_width=0.5, head_length=0.1, fc='k', ec='k')\n",
    "a[1].set_xticks([])\n",
    "a[1].set_yticks([])\n",
    "a[1].set_xlabel(\"Time\")\n",
    "a[1].set_ylabel(\"\")\n",
    "a[1].set_ylim([-0.2,2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of design matrices\n",
    "\n",
    "Back to the data generating process:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{dx_i}{dt}\\tau_i = -x_i(t) + s\\phi\\big(x_i(t)\\big) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(x_j(t)\\big)\\Bigg) + I_i(t)\n",
    "\\end{equation*}\n",
    "\n",
    "The simulations are done using the [Runge-Kutte second order method](https://lpsa.swarthmore.edu/NumInt/NumIntSecond.html##section16) to solve the differential equation.\n",
    "\n",
    "As a result [following the algebra here](https://github.com/zenkavi/NetworkGLM/blob/master/simulations/NB0_Inverting_Runge_Kutte.ipynb) the GLM to invert should be:\n",
    "\n",
    "$$\\begin{equation*}\n",
    "x_{i}(t+1) = (1-\\frac{dt}{\\tau_i}){x_{i}(t)} + \\frac{dt}{2\\tau_i}\\Bigg[gN_i(t) + s\\phi\\big(x_{i}(t)\\big) + {I}_{i}(t) - \\frac{dt}{\\tau_i}\\Bigg[-x_{i}(t) + gN_i(t) + s\\phi\\big(x_{i}(t)\\big) + {I}_{i}(t)\\Bigg] + gN_i(t+1) + s\\phi\\Bigg(x_{i}(t) + \\frac{dt}{\\tau_i}\\Bigg[-x_{i}(t) + gN_i(t) + s\\phi\\big(x_{i}(t)\\big) + {I}_{i}(t)\\Bigg]\\Bigg) + {I}_{i}(t+1)\\Bigg]\n",
    "\\end{equation*}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\begin{equation*}\n",
    "N_i(t) = \\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(x_j(t)\\big)\n",
    "\\end{equation*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accordingly the activity in the next timestep of a node is a weighted sum of current activity $x_{i}(t)$ and an adjustment amount that accounts for the network activity, recurrent activity as well as task stimulation.\n",
    "\n",
    "The adjustment is weighted by $\\frac{dt}{\\tau{t}}$. The smaller this is (the larger the time constant relative to the sampling rate) the more the activity in the next step depends on the current activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If we were to run an experiment we would not know $I_i(t)$, i.e. how the task affects each node. Instead we would only know the task structure that we impose and check for the relationship between this time course and the time course of activity in each node (operationally this means using `tasktiming` instead of `stimtimes` for the task regressor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments to run_ext_glm\n",
    "# all_nodes_ts, task_reg, weight_matrix, g, s, dt, tau, standardize=False\n",
    "\n",
    "all_nodes_ts = taskdata\n",
    "task_reg = tasktiming\n",
    "weight_matrix = W\n",
    "g = sim_args['g']\n",
    "s = sim_args['s']\n",
    "dt = sim_args['dt']\n",
    "tau = sim_args['tau']\n",
    "\n",
    "node = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "## DV\n",
    "###########################\n",
    "\n",
    "#Drop the first time point\n",
    "x_t_1 = all_nodes_ts[node,1:]\n",
    "\n",
    "###########################\n",
    "## Term 1\n",
    "###########################\n",
    "\n",
    "const1 = 1 - (dt/tau)\n",
    "\n",
    "#Drop the last time point\n",
    "x_t = all_nodes_ts[node,:-1]\n",
    "\n",
    "term1 = const1 * x_t\n",
    "\n",
    "###########################\n",
    "## Term 2\n",
    "###########################\n",
    "\n",
    "const2 = dt/(2*tau)\n",
    "\n",
    "raw_N_t = np.delete(all_nodes_ts, node, axis=0)\n",
    "phi_N_t = np.apply_along_axis(phi, 0, raw_N_t)\n",
    "incoming_weights = np.delete(weight_matrix[node,:], node, axis=0)\n",
    "incoming_weights = incoming_weights.reshape(-1,1)\n",
    "weighed_N_t = incoming_weights * phi_N_t\n",
    "\n",
    "N_t = np.sum(weighed_N_t[:,:-1], axis=0)\n",
    "g_N_t = g*N_t\n",
    "\n",
    "s_phi_x_t = s*phi(x_t)\n",
    "\n",
    "i_t = task_reg[:-1]\n",
    "\n",
    "const2_1 = dt/tau\n",
    "\n",
    "dt_tau = const2_1 * (g_N_t + s_phi_x_t + i_t - x_t)\n",
    "\n",
    "N_t_1 = np.sum(weighed_N_t[:,1:], axis=0)\n",
    "g_N_t_1 = g*N_t_1\n",
    "\n",
    "x_star = x_t + dt_tau\n",
    "s_phi_x_star = s*phi(x_star) \n",
    "\n",
    "i_t_1 = task_reg[1:]\n",
    "\n",
    "adjustment = g_N_t + s_phi_x_t + i_t - dt_tau + g_N_t_1 + s_phi_x_star + i_t_1\n",
    "\n",
    "term2 = const2 * adjustment\n",
    "\n",
    "old_des_mat = i_t.reshape(-1,1)\n",
    "new_des_mat = np.column_stack((term1, term2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 10\n",
    "plt.rcParams[\"figure.figsize\"][1] = 5\n",
    "fig, a = plt.subplots(1, 3, gridspec_kw={'width_ratios': [1, 2, 4]})\n",
    "\n",
    "a[0].set_title(\"x(t+1)\", fontdict = {'fontsize':14})\n",
    "a[1].set_title(\"cGLM design matrix\", fontdict = {'fontsize':14})\n",
    "a[2].set_title(\"eGLM design matrix\", fontdict = {'fontsize':14})\n",
    "\n",
    "sns.heatmap(x_t_1.reshape(-1,1), xticklabels=False, yticklabels=False, cbar=False, ax = a[0], vmin = 0 , vmax = 1)\n",
    "sns.heatmap(old_des_mat, yticklabels=False, cbar=False, ax = a[1], vmin = 0 , vmax = 1)\n",
    "sns.heatmap(new_des_mat, yticklabels=False, cbar=True, ax = a[2], vmin = 0 , vmax = 1)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_df = pd.DataFrame(data = {\"y\": y, \"s_phi_x\":s_phi_x, \"g_w_phi_x\":g_w_phi_x, \"i_t\":i_t})\n",
    "old_mod = smf.ols(formula = 'y ~ i_t', data = mod_df).fit()\n",
    "mid_mod = smf.ols(formula = 'y ~ s_phi_x + g_w_phi_x', data = mod_df).fit()\n",
    "new_mod = smf.ols(formula = 'y ~ s_phi_x + g_w_phi_x + i_t', data = mod_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cGLM task parameter estimate: %s\"%(str(round(old_mod.params['i_t'],3))))\n",
    "print(\"eGLM task parameter estimate: %s\"%(str(round(new_mod.params['i_t'],3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y - (s_phi_x+g_w_phi_x+i_t)\n",
    "#stimtimes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: $s$ and $g$ are network properties that you wouldn't know about in emprical task data. But with empirical data it might possible to estimate these network properties from resting state data and then plug them in for task analyses.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline calculation\n",
    "\n",
    "To assess the \"improvement\" of the model we would like to compare the task involvement estimates to a \"true\" baseline since the data is synthetic. \n",
    "\n",
    "Standard model comparison of the reduction in sum of squared residuals as a function of the degrees of freedom isn't too informative in evaluating whether the addition of the two regressors improves our description of the relationship between the task regressor and network activity because a model with more parameters will always account for more of the variance in the data. We are interested in whether the variance is attributed to the correct regressors.  \n",
    "\n",
    "Change in average activity when task is on compared to when task is off does not provide the \"true\" change in signal due to task becaus it is \"contaminated\" by network activity.  \n",
    "\n",
    "Baseline should capture how much of the change in $y$ is due to $I(t)$ separate from the effect of recurrence and functional connectivity. In other words it is the regression weight of $I(t)$ in the extended model for **noiseless data.**  \n",
    "\n",
    "This way, baseline does **NOT** depend on noise but it **DOES** depend on the node's connectivity (so it wouldn't be the same for all nodes, even all stimulated nodes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stimulated node\n",
    "\n",
    "The plot below shows the time course of one stimulated node's activity following a task on and task off period (dashed line). Additionally it also depicts the time course of each of the regressors and the predicted node activity time series from models with increasing complexity.\n",
    "\n",
    "If we were to describe the effect of task on the node's time course using the raw time course of the task activity (blue line). This would overestimate the task involvement (the classic GLM case) as it must be multiplied with a large factor to approximate the dashed line. Furthermore as seen in the model predicted values (red line) there are systematic over and under estimations using just this regressor.\n",
    "\n",
    "If we instead think of the data as a linear combination (brown line) of the task activity (blue), recurrent activity (yellow) and network activity (green) then we get a better approximation of the data. The task regressor coefficient in this case is our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 18\n",
    "plt.rcParams[\"figure.figsize\"][1] = 5\n",
    "fig, a = plt.subplots(1, 2)\n",
    "\n",
    "plt_ranges = [range(45,60), range(90,120)]\n",
    "titles = ['Task On', \"Task Off\"]\n",
    "\n",
    "for i, plt_range in enumerate(plt_ranges):\n",
    "    a[i].plot(i_t[plt_range], label = \"i_t\")\n",
    "    a[i].plot(s_phi_x[plt_range], label = \"s_phi_x\")\n",
    "    a[i].plot(g_w_phi_x[plt_range], label = \"g_w_phi_x\")\n",
    "    a[i].plot(old_mod.predict()[plt_range], label=\"y ~ i_t\")\n",
    "    a[i].plot(mid_mod.predict()[plt_range], label='y ~ s_phi_x + g_w_phi_x')\n",
    "    a[i].plot(new_mod.predict()[plt_range], label='y ~ s_phi_x + g_w_phi_x + i_t', linewidth=5)\n",
    "    a[i].plot(y[plt_range], label = \"y\", linewidth=5, linestyle='--')\n",
    "    a[i].legend()\n",
    "    a[i].set_title(titles[i], fontdict = {'fontsize':14})\n",
    "#     a[i].set_xticks([])\n",
    "    a[i].set_yticks([])\n",
    "    a[i].set_ylim([-.2,2.5])\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "plt.suptitle(\"Stimulated node\", size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-stimulated node\n",
    "\n",
    "**Why is the baseline not 0?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = 7\n",
    "\n",
    "#Drop the first time point\n",
    "y = taskdata[node,1:]\n",
    "\n",
    "#intercept\n",
    "intcp = np.ones_like(y)\n",
    "\n",
    "#Drop last time point\n",
    "s_phi_x = sim_args['s']*phi(taskdata[node,:-1])\n",
    "\n",
    "g_w_phi_x = np.delete(taskdata, node, axis=0)[:,:-1]\n",
    "g_w_phi_x = np.apply_along_axis(phi, 0, g_w_phi_x)\n",
    "cur_w = np.delete(W[node,:], node, axis=0)\n",
    "cur_w = cur_w.reshape(-1,1)\n",
    "g_w_phi_x = cur_w * g_w_phi_x\n",
    "g_w_phi_x = np.sum(g_w_phi_x, axis=0)\n",
    "g_w_phi_x = sim_args['g']*g_w_phi_x\n",
    "\n",
    "# This is external; don't know how the task affects a node\n",
    "# i_t = stimtimes[node,:-1]\n",
    "i_t = tasktiming[:-1]\n",
    "\n",
    "old_des_mat = np.column_stack((intcp, i_t))\n",
    "new_des_mat = np.column_stack((intcp, s_phi_x, g_w_phi_x, i_t))\n",
    "\n",
    "mod_df = pd.DataFrame(data = {\"y\": y, \"s_phi_x\":s_phi_x, \"g_w_phi_x\":g_w_phi_x, \"i_t\":i_t})\n",
    "old_mod = smf.ols(formula = 'y ~ i_t', data = mod_df).fit()\n",
    "mid_mod = smf.ols(formula = 'y ~ s_phi_x + g_w_phi_x', data = mod_df).fit()\n",
    "new_mod = smf.ols(formula = 'y ~ s_phi_x + g_w_phi_x + i_t', data = mod_df).fit()\n",
    "\n",
    "print(\"cGLM task parameter estimate: %s\"%(str(round(old_mod.params['i_t'],3))))\n",
    "print(\"eGLM task parameter estimate: %s\"%(str(round(new_mod.params['i_t'],3))))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"][0] = 18\n",
    "plt.rcParams[\"figure.figsize\"][1] = 5\n",
    "fig, a = plt.subplots(1, 2)\n",
    "\n",
    "plt_ranges = [range(45,60), range(90,120)]\n",
    "titles = ['Task On', \"Task Off\"]\n",
    "\n",
    "for i, plt_range in enumerate(plt_ranges):\n",
    "    a[i].plot(i_t[plt_range], label = \"i_t\")\n",
    "    a[i].plot(s_phi_x[plt_range], label = \"s_phi_x\")\n",
    "    a[i].plot(g_w_phi_x[plt_range], label = \"g_w_phi_x\")\n",
    "    a[i].plot(old_mod.predict()[plt_range], label=\"y ~ i_t\")\n",
    "    a[i].plot(mid_mod.predict()[plt_range], label='y ~ s_phi_x + g_w_phi_x')\n",
    "    a[i].plot(new_mod.predict()[plt_range], label='y ~ s_phi_x + g_w_phi_x + i_t', linewidth=5)\n",
    "    a[i].plot(y[plt_range], label = \"y\", linewidth=5, linestyle='--')\n",
    "    a[i].legend()\n",
    "    a[i].set_title(titles[i], fontdict = {'fontsize':14})\n",
    "#     a[i].set_xticks([])\n",
    "    a[i].set_yticks([])\n",
    "    a[i].set_ylim([-.2,2.5])\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "plt.suptitle(\"Non-stimulated node\", size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task parameter correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_args.update({'W':W})\n",
    "base_sim = sim_network_task_glm(args_dict=sim_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sim_network_glm(base_sim, nnods = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
