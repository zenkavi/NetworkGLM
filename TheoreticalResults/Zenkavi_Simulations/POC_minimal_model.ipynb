{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import copy\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import custom modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (eGLM_helpers.py, line 39)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/zeynepenkavi/anaconda/envs/py37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3326\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-556a548f5562>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from eGLM_helpers import phi, run_ucr_glm, run_ext_glm, make_stimtimes, sim_network_task_glm,  get_true_baseline, plot_sim_network_glm\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"../eGLM_helpers.py\"\u001b[0;36m, line \u001b[0;32m39\u001b[0m\n\u001b[0;31m    'stim_mag':.5,\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../utils/')\n",
    "\n",
    "# Helper functions for eGLM \n",
    "from eGLM_helpers import phi, run_ucr_glm, run_ext_glm, make_stimtimes, sim_network_task_glm,  get_true_baseline, plot_sim_network_glm\n",
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network structure\n",
    "\n",
    "Goal of this notebook: Create the most minimal RNN that will be used in the more extended simulations to understand how activity propogates depending on the various parameters.\n",
    "\n",
    "The network model describes change in activity as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{dx_i}{dt}\\tau_i = -x_i(t) + s\\phi\\big(x_i(t)\\big) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(x_j(t)\\big)\\Bigg) + I_i(t)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create network with 9 nodes with the following connectivity matrix. The first community (nodes 0-2) is a hub community and the other two are local communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncommunities = 3\n",
    "innetwork_dsity = .6\n",
    "outnetwork_dsity = .08\n",
    "hubnetwork_dsity = .5\n",
    "nodespercommunity = 3\n",
    "plot_network = False\n",
    "\n",
    "totalnodes = nodespercommunity*ncommunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct structural matrix\n",
    "S = model.generateStructuralNetwork(ncommunities=ncommunities,\n",
    "                                    innetwork_dsity=innetwork_dsity,\n",
    "                                    outnetwork_dsity=outnetwork_dsity,\n",
    "                                    hubnetwork_dsity=hubnetwork_dsity,\n",
    "                                    nodespercommunity=nodespercommunity,\n",
    "                                    showplot=True)\n",
    "\n",
    "plt.hlines(y=2.5, xmin = -0.5, xmax = 8.5)\n",
    "plt.hlines(y=5.5, xmin = -0.5, xmax = 8.5)\n",
    "plt.vlines(x=2.5, ymin = -0.5, ymax = 8.5)\n",
    "plt.vlines(x=5.5, ymin = -0.5, ymax = 8.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in this matrix:\n",
    "\n",
    "`W[..., x]` : column x of matrix denotes all outgoing connection weights from node x  \n",
    "`W[x, ...]` : row x of matrix denotes all incoming connection weights to node x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct synaptic matrix\n",
    "W = model.generateSynapticNetwork(S, showplot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmax = 1000\n",
    "dt = 1\n",
    "T = np.arange(0,Tmax,dt)\n",
    "\n",
    "# Construct a community affiliation vector\n",
    "Ci = np.repeat(np.arange(ncommunities),nodespercommunity) \n",
    "# Identify the regions associated with the hub network (hub network is by default the 0th network)\n",
    "hub_ind = np.where(Ci==0)[0] \n",
    "\n",
    "stimsize = nodespercommunity\n",
    "\n",
    "# This works because if there is a hub network the first nodes are the hub nodes\n",
    "stim_nodes_td = np.arange(0, stimsize, dtype=int)\n",
    "#stim_nodes_td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task structure\n",
    "\n",
    "This network is stimulated topdown (i.e. only the hub nodes) with the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = 50\n",
    "ea = 100\n",
    "iv = 200\n",
    "tasktiming, stimtimes = make_stimtimes(Tmax=1000, dt=1, stim_nodes= stim_nodes_td, stim_mag=0.5, sa = sa, ea = ea, iv = iv,\n",
    "                          ncommunities = ncommunities, nodespercommunity = nodespercommunity)\n",
    "plt.plot(tasktiming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskdata, _ = model.networkModel(W, Tmax=Tmax,dt=dt,\n",
    "                                     g=1, s=1, tau=1, I=stimtimes, \n",
    "                                     noise=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network activity time course\n",
    "\n",
    "Timeseries/activity for each node in each community.  \n",
    "\n",
    "Since only the hub network is stimulated by the task the amount of activity will depend on number (/strength) of incoming connections from hub network nodes. If a node does not have any incoming connections from the hub network its activity will not change from 0.\n",
    "\n",
    "Connections from the hub community to the other communities can be checked on the columns going out of the hub nodes (in this case the first three columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize what is going on on the network\n",
    "#Three scatter plots with three curves for the timeseries/activity of each node in that community\n",
    "taskdata_df = pd.DataFrame(taskdata)\n",
    "taskdata_df['node_num'] = taskdata_df.index\n",
    "taskdata_df['com_num'] = [0,0,0,1,1,1,2,2,2]\n",
    "taskdata_df = taskdata_df.melt(id_vars = ['node_num', 'com_num'])\n",
    "taskdata_df = taskdata_df.rename(columns={\"variable\": \"time\", \"value\": \"activity\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 20\n",
    "plt.rcParams[\"figure.figsize\"][1] = 5\n",
    "fig, a = plt.subplots(1, 3)\n",
    "\n",
    "for cur_com in taskdata_df.com_num.unique():\n",
    "    \n",
    "    cur_vals = [\"C\"+str(x) for x in range(len(taskdata_df.query(\"com_num==@cur_com\").node_num.unique()))]\n",
    "    cur_col_lookup = dict(zip(taskdata_df.query(\"com_num==@cur_com\").node_num.unique(), cur_vals))\n",
    "    \n",
    "    for cur_node in taskdata_df.query(\"com_num==@cur_com\").node_num.unique():\n",
    "        tmp = taskdata_df.query(\"com_num==@cur_com & node_num==@cur_node\")\n",
    "        a[cur_com].plot(tmp['time'], tmp['activity'], color = cur_col_lookup[cur_node], label = cur_node)\n",
    "        a[cur_com].set_ylim([-0.2,2])\n",
    "        a[cur_com].set_title(\"com_num = %s\"%(str(cur_com)))\n",
    "        a[cur_com].legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that activity builds up and decreases in several time steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 14\n",
    "plt.rcParams[\"figure.figsize\"][1] = 5\n",
    "fig, a = plt.subplots(1, 2)\n",
    "\n",
    "node = 0\n",
    "task_on_t = np.where(np.diff(tasktiming) != 0)[0][0]\n",
    "task_off_t = np.where(np.diff(tasktiming) != 0)[0][1]\n",
    "range_start = 45\n",
    "range_end = 70\n",
    "plt_ranges = [range(range_start, range_end), range(range_start+50, range_end+50)]\n",
    "\n",
    "a[0].plot(taskdata[node, plt_ranges[0]])\n",
    "a[0].annotate(\"Task On\", xy=(task_on_t - range_start-1, 0.35), xytext=(task_on_t - range_start-1, 0.35))\n",
    "a[0].arrow(task_on_t - range_start, 0.3, 0, -0.2, head_width=0.5, head_length=0.1, fc='k', ec='k')\n",
    "a[0].set_xticks([])\n",
    "a[0].set_yticks([])\n",
    "a[0].set_xlabel(\"Time\")\n",
    "a[0].set_ylabel(\"Activity\")\n",
    "a[0].set_ylim([-0.2,2])\n",
    "\n",
    "a[1].plot(taskdata[node, plt_ranges[1]])\n",
    "a[1].annotate(\"Task Off\", xy=(task_off_t - (range_start+50)-1,  max(taskdata[node]) - .4), xytext=(task_off_t - (range_start+50)-1,  max(taskdata[node]) - .4))\n",
    "a[1].arrow(task_off_t - (range_start+50), max(taskdata[node]) - .3, 0, 0.2, head_width=0.5, head_length=0.1, fc='k', ec='k')\n",
    "a[1].set_xticks([])\n",
    "a[1].set_yticks([])\n",
    "a[1].set_xlabel(\"Time\")\n",
    "a[1].set_ylabel(\"\")\n",
    "a[1].set_ylim([-0.2,2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of design matrices\n",
    "\n",
    "Back to the data generating process:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{dx_i}{dt}\\tau_i = -x_i(t) + s\\phi\\big(x_i(t)\\big) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(x_j(t)\\big)\\Bigg) + I_i(t)\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "x_i(t+1) = \\frac{dx_i}{dt}\\tau_i + x_i(t)\n",
    "\\end{equation*}\n",
    "\n",
    "So the GLM to invert should be:\n",
    "\n",
    "\\begin{equation*}\n",
    "x_i(t+1) = s\\phi\\big(x_i(t)\\big) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(x_j(t)\\big)\\Bigg) + I_i(t)\n",
    "\\end{equation*}\n",
    "\n",
    "The extended GLM contains additional regressors to account for the node's own activity (recurrence) and the network activity (functional connectivity)\n",
    "\n",
    "If we were to run an experiment we would not know $I_i(t)$, i.e. how the task affects each node. Instead we would only know the task structure that we impose and check for the relationship between this time course and the time course of activity in each node (operationally this means using `tasktiming` instead of `stimtimes` for the task regressor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1\n",
    "g = 1\n",
    "node = 0\n",
    "\n",
    "#Drop the first time point\n",
    "y = taskdata[node,1:]\n",
    "\n",
    "#intercept\n",
    "intcp = np.ones_like(y)\n",
    "\n",
    "#Drop last time point\n",
    "s_phi_x = s*phi(taskdata[node,:-1])\n",
    "\n",
    "g_w_phi_x = np.delete(taskdata, node, axis=0)[:,:-1]\n",
    "g_w_phi_x = np.apply_along_axis(phi, 0, g_w_phi_x)\n",
    "cur_w = np.delete(W[node,:], node, axis=0)\n",
    "cur_w = cur_w.reshape(-1,1)\n",
    "g_w_phi_x = cur_w * g_w_phi_x\n",
    "g_w_phi_x = np.sum(g_w_phi_x, axis=0)\n",
    "g_w_phi_x = g*g_w_phi_x\n",
    "\n",
    "# This is external; don't know how the task affects a node\n",
    "# i_t = stimtimes[node,:-1]\n",
    "i_t = tasktiming[:-1]\n",
    "\n",
    "old_des_mat = np.column_stack((intcp, i_t))\n",
    "new_des_mat = np.column_stack((intcp, s_phi_x, g_w_phi_x, i_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 10\n",
    "plt.rcParams[\"figure.figsize\"][1] = 5\n",
    "fig, a = plt.subplots(1, 3, gridspec_kw={'width_ratios': [1, 2, 4]})\n",
    "\n",
    "a[0].set_title(\"Y\", fontdict = {'fontsize':14})\n",
    "a[1].set_title(\"cGLM design matrix\", fontdict = {'fontsize':14})\n",
    "a[2].set_title(\"eGLM design matrix\", fontdict = {'fontsize':14})\n",
    "\n",
    "sns.heatmap(y.reshape(-1,1), xticklabels=False, yticklabels=False, cbar=False, ax = a[0], vmin = 0 , vmax = 1)\n",
    "sns.heatmap(old_des_mat, xticklabels=False, yticklabels=False, cbar=False, ax = a[1], vmin = 0 , vmax = 1)\n",
    "sns.heatmap(new_des_mat, xticklabels=False, yticklabels=False, cbar=True, ax = a[2], vmin = 0 , vmax = 1)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_df = pd.DataFrame(data = {\"y\": y, \"s_phi_x\":s_phi_x, \"g_w_phi_x\":g_w_phi_x, \"i_t\":i_t})\n",
    "old_mod = smf.ols(formula = 'y ~ i_t', data = mod_df).fit()\n",
    "mid_mod = smf.ols(formula = 'y ~ s_phi_x + g_w_phi_x', data = mod_df).fit()\n",
    "new_mod = smf.ols(formula = 'y ~ s_phi_x + g_w_phi_x + i_t', data = mod_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cGLM task parameter estimate: %s\"%(str(round(old_mod.params['i_t'],3))))\n",
    "print(\"eGLM task parameter estimate: %s\"%(str(round(new_mod.params['i_t'],3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: $s$ and $g$ are network properties that you wouldn't know about in emprical task data. But these might be estimated from resting state data and then plugged in for task analyses.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline calculation\n",
    "\n",
    "To assess the \"improvement\" of the model we would like to compare the task involvement estimates to a \"true\" baseline since the data is synthetic. \n",
    "\n",
    "Standard model comparison of the reduction in sum of squared residuals as a function of the degrees of freedom isn't too informative with respect to our desired goal because a model with more parameters will always account for more of the variance in the data. We are interested in whether the variance is attributed to the correct regressors.  \n",
    "\n",
    "Change in average activity when task is on compared to when task is off does not provide the \"true\" change in signal due to task becaus it is \"contaminated\" by network activity.  \n",
    "\n",
    "Baseline should capture how much of the change in $y$ is due to $I(t)$ separate from the effect of recurrence and functional connectivity. In other words it is the regression weight of $I(t)$ in the extended model for **noiseless data**\n",
    "This way, baseline does **NOT** depend on noise but it **DOES** depend on the node's connectivity (so it wouldn't be the same for all nodes, even all stimulated nodes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stimulated node\n",
    "\n",
    "The plot below shows the time course of one stimulated node's activity following a task on and task off period (dashed line). Additionally it also depicts the time course of each of the regressors and the predicted node activity time series from models with increasing complexity.\n",
    "\n",
    "If we were to describe the effect of task on the node's time course using the raw time course of the task activity (blue line). This would overestimate the task involvement (the classic GLM case) as it must be multiplied with a large factor to approximate the dashed line. Furthermore as seen in the model predicted values (red line) there are systematic over and under estimations using just this regressor.\n",
    "\n",
    "If we instead think of the data as a linear combination (brown line) of the task activity (blue), recurrent activity (yellow) and network activity (green) then we get a better approximation of the data. The task regressor coefficient in this case is our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 18\n",
    "plt.rcParams[\"figure.figsize\"][1] = 5\n",
    "fig, a = plt.subplots(1, 2)\n",
    "\n",
    "plt_ranges = [range(45,60), range(90,120)]\n",
    "titles = ['Task On', \"Task Off\"]\n",
    "\n",
    "for i, plt_range in enumerate(plt_ranges):\n",
    "    a[i].plot(i_t[plt_range], label = \"i_t\")\n",
    "    a[i].plot(s_phi_x[plt_range], label = \"s_phi_x\")\n",
    "    a[i].plot(g_w_phi_x[plt_range], label = \"g_w_phi_x\")\n",
    "    a[i].plot(old_mod.predict()[plt_range], label=\"y ~ i_t\")\n",
    "    a[i].plot(mid_mod.predict()[plt_range], label='y ~ s_phi_x + g_w_phi_x')\n",
    "    a[i].plot(new_mod.predict()[plt_range], label='y ~ s_phi_x + g_w_phi_x + i_t', linewidth=5)\n",
    "    a[i].plot(y[plt_range], label = \"y\", linewidth=5, linestyle='--')\n",
    "    a[i].legend()\n",
    "    a[i].set_title(titles[i], fontdict = {'fontsize':14})\n",
    "    a[i].set_xticks([])\n",
    "    a[i].set_yticks([])\n",
    "    a[i].set_ylim([-.2,2.5])\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "plt.suptitle(\"Stimulated node\", size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_df['task_on'] = np.where(mod_df['i_t']==0,\"off\",\"on\")\n",
    "sns.pairplot(mod_df, hue='task_on', vars=mod_df.columns[:-1], diag_kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-stimulated node\n",
    "\n",
    "**Why is the baseline not 0?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1\n",
    "g = 1\n",
    "node = 6\n",
    "\n",
    "#Drop the first time point\n",
    "y = taskdata[node,1:]\n",
    "\n",
    "#intercept\n",
    "intcp = np.ones_like(y)\n",
    "\n",
    "#Drop last time point\n",
    "s_phi_x = s*phi(taskdata[node,:-1])\n",
    "\n",
    "g_w_phi_x = np.delete(taskdata, node, axis=0)[:,:-1]\n",
    "g_w_phi_x = np.apply_along_axis(phi, 0, g_w_phi_x)\n",
    "cur_w = np.delete(W[node,:], node, axis=0)\n",
    "cur_w = cur_w.reshape(-1,1)\n",
    "g_w_phi_x = cur_w * g_w_phi_x\n",
    "g_w_phi_x = np.sum(g_w_phi_x, axis=0)\n",
    "g_w_phi_x = g*g_w_phi_x\n",
    "\n",
    "# This is external; don't know how the task affects a node\n",
    "# i_t = stimtimes[node,:-1]\n",
    "i_t = tasktiming[:-1]\n",
    "\n",
    "old_des_mat = np.column_stack((intcp, i_t))\n",
    "new_des_mat = np.column_stack((intcp, s_phi_x, g_w_phi_x, i_t))\n",
    "\n",
    "mod_df = pd.DataFrame(data = {\"y\": y, \"s_phi_x\":s_phi_x, \"g_w_phi_x\":g_w_phi_x, \"i_t\":i_t})\n",
    "old_mod = smf.ols(formula = 'y ~ i_t', data = mod_df).fit()\n",
    "mid_mod = smf.ols(formula = 'y ~ s_phi_x + g_w_phi_x', data = mod_df).fit()\n",
    "new_mod = smf.ols(formula = 'y ~ s_phi_x + g_w_phi_x + i_t', data = mod_df).fit()\n",
    "\n",
    "print(\"cGLM task parameter estimate: %s\"%(str(round(old_mod.params['i_t'],3))))\n",
    "print(\"eGLM task parameter estimate: %s\"%(str(round(new_mod.params['i_t'],3))))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"][0] = 18\n",
    "plt.rcParams[\"figure.figsize\"][1] = 5\n",
    "fig, a = plt.subplots(1, 2)\n",
    "\n",
    "plt_ranges = [range(45,60), range(90,120)]\n",
    "titles = ['Task On', \"Task Off\"]\n",
    "\n",
    "for i, plt_range in enumerate(plt_ranges):\n",
    "    a[i].plot(i_t[plt_range], label = \"i_t\")\n",
    "    a[i].plot(s_phi_x[plt_range], label = \"s_phi_x\")\n",
    "    a[i].plot(g_w_phi_x[plt_range], label = \"g_w_phi_x\")\n",
    "    a[i].plot(old_mod.predict()[plt_range], label=\"y ~ i_t\")\n",
    "    a[i].plot(mid_mod.predict()[plt_range], label='y ~ s_phi_x + g_w_phi_x')\n",
    "    a[i].plot(new_mod.predict()[plt_range], label='y ~ s_phi_x + g_w_phi_x + i_t', linewidth=5)\n",
    "    a[i].plot(y[plt_range], label = \"y\", linewidth=5, linestyle='--')\n",
    "    a[i].legend()\n",
    "    a[i].set_title(titles[i], fontdict = {'fontsize':14})\n",
    "    a[i].set_xticks([])\n",
    "    a[i].set_yticks([])\n",
    "    a[i].set_ylim([-.2,2.5])\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "plt.suptitle(\"Non-stimulated node\", size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation between regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_df['task_on'] = np.where(mod_df['i_t']==0,\"off\",\"on\")\n",
    "sns.pairplot(mod_df, hue='task_on', vars=mod_df.columns[:-1], diag_kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task parameter correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1\n",
    "tau = 1\n",
    "g = 1\n",
    "s = 1 \n",
    "stim_mag = .5\n",
    "sa = 50\n",
    "ea = 100\n",
    "iv = 200\n",
    "\n",
    "base_sim = sim_network_task_glm(ncommunities = ncommunities, \n",
    "                         nodespercommunity = nodespercommunity, \n",
    "                         dt = dt, tau = tau, g = g, s = s, \n",
    "                         Tmax = Tmax, \n",
    "                         stimsize = nodespercommunity, \n",
    "                         stim_mag = stim_mag,\n",
    "                         W = W,\n",
    "                         taskdata = taskdata,\n",
    "                         tasktiming = tasktiming,\n",
    "                         sa = sa,\n",
    "                         ea = ea,\n",
    "                         iv = iv,\n",
    "                         standardize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sim_network_glm(base_sim, nnods = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
